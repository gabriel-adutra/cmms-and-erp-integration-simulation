# TracOS ↔ Client Integration System

## About the Project

This project implements an asynchronous Python service that simulates a bidirectional integration between Tractian's TracOS CMMS and a customer's ERP system. The system synchronizes work orders between the two systems, performing inbound (Client → TracOS) and outbound (TracOS → Client) flows with data translation and validation.

## Architecture

The system was designed with a clear separation of responsibilities to make it easy to add new integrations without changing existing modules:

### Main Modules
- `client_adapter.py` - Read/write operations with the client system (JSON files).
- `tracos_adapter.py` - Read/write operations with the TracOS system (MongoDB).
- `translator.py` - Bidirectional data translation between systems.
- `config.py` - Centralized configuration via environment variables.
- `main.py` - Main orchestrator of the integration pipeline.

### System Characteristics
- Asynchronous: Non-blocking MongoDB operations for better performance.
- Resilient: Robust handling of I/O errors and transient network failures.
- Idempotent: Safe operations for retry using upsert with unique keys.
- Extensible: Modular architecture enables adding new systems easily.

### Technical Highlights Implemented
- Singleton Pattern: Centralized configuration with single load.
- Exponential Backoff Retry: Automatic recovery from transient failures (1s → 2s → 4s).
- Structured Logging: Clear, organized logs for debugging.
- Resource Management: Smart reuse of MongoDB connections with cleanup.
- Strict Validation: Required fields and types validated with specific error messages.
- Failure Isolation: A problematic file doesn't stop the entire pipeline.

## How the System Works

### Inbound Flow (Client → TracOS)
1. Read: Processes JSON files from the `data/inbound/` folder (simulating client API responses).
2. Validate: Checks required fields (`orderNo`, `summary`, `creationDate`).
3. Translate: Converts client format to TracOS format (e.g., boolean statuses → enums).
4. Persist: Saves/updates records in MongoDB with `isSynced=false`.

### Outbound Flow (TracOS → Client)
1. Query: Fetches work orders in MongoDB with `isSynced=false`.
2. Translate: Converts TracOS format to the client format.
3. Generate: Creates JSON files in `data/outbound/` (ready to be "sent" to the client).
4. Mark: Updates records in MongoDB with `isSynced=true` and `syncedAt` timestamp.

### Data Normalization
- Dates: Normalized to UTC ISO 8601.
- Status: Mapping between enums (client uses booleans, TracOS uses strings).
- Fields: Translation between different names and structures.

### Important Business Rule
Default Status for Work Orders: When a client work order has no active status (all boolean fields are `false`), the system automatically applies `status="pending"` in TracOS. This ensures every work order has a valid state in the system.

Example: Client sends `isPending: false, isDone: false, isCanceled: false, isOnHold: false` → System applies `"pending"` → Returns `isPending: true` on the sync back.

## Project Structure

```
tractian_integrations_engineering_technical_test/
├── docker-compose.yml              # MongoDB container
├── pyproject.toml                  # Poetry dependencies
├── setup.py                        # Initialization script with sample data
├── .env                            # Environment variables
├── data/
│   ├── inbound/                    # Input JSON files (Client → TracOS)
│   └── outbound/                   # Output JSON files (TracOS → Client)
├── src/
│   ├── main.py                     # Main script - runs the full pipeline
│   ├── client_adapter.py           # Module for client system operations
│   ├── tracos_adapter.py           # Module for TracOS system operations
│   ├── translator.py               # Module for format translation
│   └── config.py                   # Centralized configuration
└── tests/
    └── test_integration.py         # End-to-end tests
```

---

## Prerequisites

Make sure you have installed:
- Python 3.11.x
- Docker and Docker Compose
- Poetry for dependency management

## Environment Setup

Before running the commands below, navigate to the project directory:
```bash
cd tractian_integrations_engineering_technical_test/
```

### 1. Install Dependencies
```bash
# Install Poetry (if needed)
curl -sSL https://install.python-poetry.org | python3 -

# Install project dependencies
poetry install
```

### 2. Start MongoDB
```bash
# Start MongoDB container
docker compose up -d

# Verify the container is running
docker ps
```

### 3. Initialize Sample Data
```bash
# Create sample data (TracOS + Client)
poetry run python setup.py
```

### 4. Run the Pipeline
```bash
# Run the full bidirectional integration
poetry run python src/main.py
```

### 5. Check Results
```bash
# Check files generated by the pipeline
ls data/outbound/
```

Expected: 10 JSON files named like `workorder_{number}.json` (files are overwritten on each run).

## Tests

### Run End-to-End Tests
```bash
# Simple run
poetry run pytest

# Run with detailed logs (recommended)
poetry run pytest -v -s
```

### What the Tests Validate
- Full pipeline: inbound flow → MongoDB → outbound
- Correct data translation between Client ↔ TracOS formats
- Integrity: input data matches the output data
- Error handling and appropriate logging

## Troubleshooting

### Common Issues

MongoDB doesn't connect:
```bash
# Check if the container is running
docker ps | grep mongo

# Restart if needed
docker compose down && docker compose up -d
```

Tests failing:
```bash
# Clean environment and start over
docker compose down -v
docker compose up -d
poetry run pytest -v -s
```

Data not showing up:
```bash
# Check if sample data was created
ls data/inbound/
# If empty, run: poetry run python setup.py
```

---

## Configuration

### Environment Variables
The `.env` file contains the required settings:
```bash
MONGO_URI=mongodb://localhost:27017/tractian
MONGO_DATABASE=tractian
MONGO_COLLECTION=workorders
DATA_INBOUND_DIR=./data/inbound  
DATA_OUTBOUND_DIR=./data/outbound
```

### .env behavior and precedence (python-decouple)
- Automatic loading: keys are read automatically from `.env` if present at the project root.
- Precedence: exported environment variables > values from `.env` > code defaults.
- Safe defaults: if there's no export and no `.env`, default values are used:
  - `MONGO_URI = mongodb://localhost:27017`
  - `MONGO_DATABASE=tractian`
  - `MONGO_COLLECTION=workorders`
  - `DATA_INBOUND_DIR = ./data/inbound`
  - `DATA_OUTBOUND_DIR = ./data/outbound`
- Note: empty values still count as a value. Avoid accidentally setting `MONGO_URI=""`.

### Logging Policy
- INFO: processing milestones (pipeline start/end, totals processed, configuration success).
- DEBUG: details and payloads (e.g., full record contents), useful for local investigation.
- WARNING: recoverable anomalous situations (e.g., invalid file ignored).
- ERROR: non-recoverable failures for the current step (e.g., error after all retry attempts).
Recommendation: use INFO for day-to-day; enable DEBUG only for diagnostics.


### Compliance checklist with project requirements listed in project_requirements.md:
- Inbound (read, validate, translate, upsert to Mongo): PASS
- Outbound (fetch `isSynced=false`, translate, write, mark `isSynced=true` + `syncedAt`): PASS
- Normalization (UTC ISO 8601 dates; enums/status): PASS
- Resilience (clear logs, robust I/O, simple retry for Mongo): PASS
- Config via environment variables (with optional `.env`): PASS
- Complete README (structure, how to run, architecture): PASS
- Automated end-to-end test with pytest: PASS


## Data Examples

### Inbound Work Order - Client input:
```json
{
  "orderNo": 1,
  "isCanceled": true,
  "isDeleted": false,
  "isDone": false,
  "isOnHold": false,
  "isPending": false,
  "summary": "Example workorder #1",
  "creationDate": "2025-09-30T23:04:29.045089+00:00",
  "lastUpdateDate": "2025-10-01T00:04:29.045089+00:00",
  "deletedDate": null
}
```

### Work Order in TracOS (Internal MongoDB) after conversion (Client → TracOS):
```json
{
  "_id": "ObjectId('69029d7dbc2225d88a00780d')",
  "number": 1,
  "status": "cancelled",
  "title": "Example workorder #1",
  "description": "Example workorder #1 description",
  "createdAt": "2025-09-30T23:04:29.045Z",
  "updatedAt": "2025-10-29T23:04:29.685Z",
  "deleted": false,
  "isSynced": false
}
```

### Work Order in Outbound after conversion (TracOS → Client):
```json
{
  "orderNo": 1,
  "summary": "Example workorder #1",
  "creationDate": "2025-09-30T23:04:29.045000+00:00",
  "lastUpdateDate": "2025-10-29T23:04:29.685000+00:00",
  "isDeleted": false,
  "deletedDate": null,
  "isDone": false,
  "isCanceled": true,
  "isOnHold": false,
  "isPending": false,
  "isActive": false
}
```

Note: MongoDB stores datetimes with millisecond precision; microseconds may be truncated (e.g., 374263 → 374000).

### Work Order in TracOS (Internal MongoDB) after synchronization:
```json
{
  "_id": "ObjectId('69029d7dbc2225d88a00780d')",
  "number": 1,
  "status": "cancelled", 
  "title": "Example workorder #1",
  "description": "Example workorder #1 description",
  "createdAt": "2025-09-30T23:04:29.045Z",
  "updatedAt": "2025-10-29T23:04:29.685Z",
  "deleted": false,
  "isSynced": true,
  "syncedAt": "2025-10-29T23:04:29.788Z"
}
```

---

*TracOS ↔ Client integration system implemented with a focus on modularity, resilience, and ease of extension to new systems.*# TracOS ↔ Client Integration System